{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Esercizio2_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4V_agDv38d6I","executionInfo":{"status":"ok","timestamp":1637001190914,"user_tz":-60,"elapsed":2245,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEInUY_Ntk0qYSRX-eqmGpqItXS1XWkFeYpUuidA=s64","userId":"17302508768599631067"}},"outputId":"eba9b100-d934-4416-de32-087a4141d6c4"},"source":["import math\n","import nltk\n","from nltk.corpus import wordnet as wn\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.probability import FreqDist\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","stop_words_list = []\n","lemmatizer = WordNetLemmatizer()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"d9ebLCNW8qk3"},"source":["#Metodi ausiliari"]},{"cell_type":"code","metadata":{"id":"wuRpN8ZD8oVl","executionInfo":{"status":"ok","timestamp":1637001190915,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEInUY_Ntk0qYSRX-eqmGpqItXS1XWkFeYpUuidA=s64","userId":"17302508768599631067"}}},"source":["# Ritorna il POS TAG di una parola\n","def get_wordnet_pos(word):\n","  treebank_tag = [tag for (word, tag) in nltk.pos_tag(nltk.word_tokenize(word))][0]\n","  if treebank_tag.startswith('J'):\n","    return wn.ADJ\n","  elif treebank_tag.startswith('V'):\n","    return wn.VERB\n","  elif treebank_tag.startswith('N'):\n","    return wn.NOUN\n","  elif treebank_tag.startswith('R'):\n","    return wn.ADV\n","  else:\n","    return ''\n","\n","\n","# Ritorna una lista con le stop words\n","def get_stop_words():\n","  if len(stop_words_list) == 0:\n","    f = open(\"./stop_words_FULL.txt\", \"r\")\n","    for x in f:\n","      stop_words_list.append(x)\n","\n","  return stop_words_list + ['’']\n","\n","\n","# Da una frase ritorna una lista con le singole parole (lemmi) rimuovendo le parole inutili (stop words..)\n","def get_list_of_gains_words(sentence):\n","  list_words_lemma = []\n","  # aus_list_words = sentence.split()\n","  aus_list_words = word_tokenize(sentence)\n","  stop_words_list = get_stop_words()\n","\n","  for w in aus_list_words:\n","    if w.lower() not in stop_words_list:\n","      pos_tag = get_wordnet_pos(w)\n","      if pos_tag != '':\n","        list_words_lemma.append(lemmatizer.lemmatize(w.lower(), pos_tag))\n","\n","  return list_words_lemma\n","\n","\n","def read_text_file():\n","    return open(\"pasta2.1.txt\", \"r\").read()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVEdfzm66E6H","executionInfo":{"status":"ok","timestamp":1637001190916,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEInUY_Ntk0qYSRX-eqmGpqItXS1XWkFeYpUuidA=s64","userId":"17302508768599631067"}},"outputId":"50f84eec-3b48-446c-888e-b3def02130eb"},"source":["# il testo è la prima parte di: https://en.wikipedia.org/wiki/Pasta\n","# Wikipedia suddivide il testo così:\n","# 0 - 2\n","# 3 - 6\n","# 8 - 11\n","# 12 - 17\n","# 18 - 19\n","\n","# restituisce un array in cui per ciascun elemento contiene le parole di una frase con associata la loro frequenza\n","# all'interno della frase\n","def get_sentences_with_tf(text):\n","  #sents_tf sara una lista che contiene tanti dizionari quante sono le frasi\n","  sents_tf = []\n","  #tokenized_sents contiene il nostro testo diviso per frasi, ('frase1', 'frase2'), sent_tokenize è un metodo di nltk\n","  tokenized_sents = sent_tokenize(text)\n","  for idx in range(len(tokenized_sents)):\n","    sents_tf.append({})\n","    #contiamo quante volte una determinata parola compare all interno della nostra frase \"tokenized_sents\"\n","    #usiamo FreqDist per calcolare la frequenza dei token\n","    fdist = FreqDist(word.lower() for word in word_tokenize(tokenized_sents[idx]))\n","    for word in word_tokenize(tokenized_sents[idx]):\n","      sents_tf[idx][word]=fdist.freq(word)\n","    \n","    #print(\"sents_tf \" + str(sents_tf))\n","\n","  return sents_tf\n","\n","\n","# funzione che segmenta il testo (text) in num_sections sezioni\n","def segment(text, num_sections):\n","  sents_tf = get_sentences_with_tf(text)\n","  #print(type(sents_tf))\n","  len_section = int(len(sents_tf) / (num_sections - 1)) # all'inizio sezioni stessa lunghezza\n","  #questa lista conterra gli indici dei vari break point, che all inizio saranno di uguale lunghezza e coincidono con\n","  #le varie sezioni \n","  sections = [0]\n","\n","  idx = len_section\n","  # Scorre le sezioni\n","  while idx <= len(sents_tf):\n","\n","    #instanziamo min_sim a infinito e poi sara diminuito di volta in volta\n","    min_sim = math.inf\n","    idx_min_sim = 0\n","    # Scorre le frasi della sezione\n","    for jdx in range(idx - len_section, idx - 1): # cerchi nella sezione il punto di minimo\n","      #confrontiamo ogni frase con quella successiva, cercando la coppia di frasi che mi da il break point\n","      #ossia quelle piu dissimili tra di loro\n","      sim = similarity(sents_tf[jdx], sents_tf[jdx + 1])\n","      if sim < min_sim:\n","        min_sim = sim\n","        #mi salvo quali frasi mi davano il break point\n","        idx_min_sim = jdx\n","\n","    # Dalla frase successiva al minimo, inizia l'altra sezione\n","    idx_min_sim += 1\n","\n","    sections.append(idx_min_sim)\n","    #serve a passare alla sezione successiva, quindi passiaomo al blocco successivo(0,1,3,7..)\n","    idx += len_section\n","\n","  sections.append(len(sents_tf))\n","\n","  return sections\n","\n","\n","# è una misura di similarità che tiene conto delle frequenze delle parole per ogni frase.\n","# calcola l'overlap delle due frasi.\n","# Per ogni parola dell'overlap somma la media delle frequenze della parole all'interno delle due frasi\n","# Normalizza la somma sulla lunghezza dell'intersezione\n","def similarity(s1, s2):\n","  sim = 0\n","  overlap = set.intersection(set(s1.keys()), set(s2.keys()))\n","\n","  if len(overlap) > 0:\n","    for word in overlap:\n","      sim += (s1[word] + s2[word]) / 2  # media fra le due frequenze\n","\n","    #qui si normalizza sulla lunghezza delle intersezioni\n","    sim /= len(overlap)\n","\n","  return sim\n","\n","\n","def print_results(sections,sentences):\n","  #per ogni sezione\n","  for idx in range(len(sections) - 1):\n","    #la sezione inizia alla riga  start_section e finsice alla riga end_section\n","    # alla posizione idx e idx+1 dell'array sections\n","    start_section = sections[idx]\n","    end_section = sections[idx + 1] #\n","\n","    print(\"\\n\\n############################ Sezione\", idx + 1, \"############################\")\n","    for jdx in range(start_section, end_section):\n","      print(sentences[jdx])\n","\n","\n","text = read_text_file()\n","num_sections = 5\n","sections = segment(text, num_sections)\n","\n","\n","#Stampo riga inizio e fine di ogni sezione (il secondo numero è escluso)\n","for idx in range(len(sections) - 1):\n","  print(\"Sezione\", idx + 1, \":\", sections[idx], \"-\", sections[idx + 1] - 1)\n","\n","\n","\n","\n","sentences = sent_tokenize(text)\n","# stampo il testo diviso per sezioni\n","print_results(sections,sentences)\n","\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sezione 1 : 0 - 0\n","Sezione 2 : 1 - 5\n","Sezione 3 : 6 - 10\n","Sezione 4 : 11 - 12\n","Sezione 5 : 13 - 18\n","\n","\n","############################ Sezione 1 ############################\n","Pasta (US: /ˈpɑːstə/, UK: /ˈpæstə/; Italian pronunciation: [ˈpasta]) is a type of food typically made from an unleavened dough of wheat flour mixed with water or eggs, and formed into sheets or other shapes, then cooked by boiling or baking.\n","\n","\n","############################ Sezione 2 ############################\n","Rice flour, or legumes such as beans or lentils, are sometimes used in place of wheat flour to yield a different taste and texture, or as a gluten-free alternative.\n","Pasta is a staple food of Italian cuisine.\n","[1][2]\n","Pastas are divided into two broad categories: dried (pasta secca) and fresh (pasta fresca).\n","Most dried pasta is produced commercially via an extrusion process, although it can be produced at home.\n","Fresh pasta is traditionally produced by hand, sometimes with the aid of simple machines.\n","\n","\n","############################ Sezione 3 ############################\n","[3] Fresh pastas available in grocery stores are produced commercially by large-scale machines.\n","Both dried and fresh pastas come in a number of shapes and varieties, with 310 specific forms known by over 1300 documented names.\n","[4] In Italy, the names of specific pasta shapes or types often vary by locale.\n","For example, the pasta form cavatelli is known by 28 different names depending upon the town and region.\n","Common forms of pasta include long and short shapes, tubes, flat shapes or sheets, miniature shapes for soup, those meant to be filled or stuffed, and specialty or decorative shapes.\n","\n","\n","############################ Sezione 4 ############################\n","[5]\n","As a category in Italian cuisine, both fresh and dried pastas are classically used in one of three kinds of prepared dishes: as pasta asciutta (or pastasciutta), cooked pasta is plated and served with a complementary sauce or condiment; a second classification of pasta dishes is pasta in brodo, in which the pasta is part of a soup-type dish.\n","A third category is pasta al forno, in which the pasta is incorporated into a dish that is subsequently baked in the oven.\n","\n","\n","############################ Sezione 5 ############################\n","[6] Pasta dishes are generally simple, but individual dishes vary in preparation.\n","Some pasta dishes are served as a small first course or for light lunches, such as pasta salads.\n","Other dishes may be portioned larger and used for dinner.\n","Pasta sauces similarly may vary in taste, color and texture.\n","[7]\n","In terms of nutrition, cooked plain pasta is 31% carbohydrates (mostly starch), 6% protein, and low in fat, with moderate amounts of manganese, but pasta generally has low micronutrient content.\n","Pasta may be enriched or fortified, or made from whole grains.\n"]}]},{"cell_type":"markdown","metadata":{"id":"GJ54LeFy8c5o"},"source":[""]}]}